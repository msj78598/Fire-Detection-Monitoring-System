import streamlit as st
import json
import os
import hashlib
import torch
import cv2
from PIL import Image
from datetime import datetime
from playsound import playsound
import pandas as pd

# ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="Fire Detection Monitoring", page_icon="ğŸ”¥", layout="wide")

# Ø´Ø±ÙŠØ· Ø¬Ø§Ù†Ø¨ÙŠ Ù„Ù„Ø¥Ø¯Ø§Ø±Ø©
st.sidebar.title("âš™ï¸ Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©")

# Ø¥Ø¶Ø§ÙØ© Ø®ÙŠØ§Ø± Ù„Ø¥ØµØ¯Ø§Ø± ØªÙ‚Ø±ÙŠØ± Excel
st.sidebar.subheader("ğŸ“Š Ø¥ØµØ¯Ø§Ø± ØªÙ‚Ø±ÙŠØ±")

# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙØªØ±Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
start_date = st.sidebar.date_input("ğŸ“… ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©")
end_date = st.sidebar.date_input("ğŸ“… ØªØ§Ø±ÙŠØ® Ø§Ù„Ù†Ù‡Ø§ÙŠØ©")

# Ø²Ø± Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
if st.sidebar.button("Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙ‚Ø±ÙŠØ±"):
    if "fire_detections" in st.session_state and st.session_state.fire_detections:
        filtered_detections = [
            detection for detection in st.session_state.fire_detections
            if start_date <= datetime.strptime(detection['time'], "%Y-%m-%d %H:%M:%S").date() <= end_date
        ]

        if filtered_detections:
            df = pd.DataFrame(filtered_detections)
            image_folder = "C:/asd8/"
            df['image_link'] = df['image'].apply(lambda x: f'=HYPERLINK("{image_folder}{x}", "Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø©")')

            excel_file = "fire_detections_report.xlsx"
            df.to_excel(excel_file, index=False)

            with open(excel_file, "rb") as file:
                st.sidebar.download_button(
                    label="ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ğŸ“¥",
                    data=file,
                    file_name=excel_file,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
        else:
            st.sidebar.error("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø§ÙƒØªØ´Ø§ÙØ§Øª ÙÙŠ Ø§Ù„ÙØªØ±Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©.")
    else:
        st.sidebar.error("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø§ÙƒØªØ´Ø§ÙØ§Øª Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙ‚Ø±ÙŠØ±.")

# Ù†Ø¸Ø§Ù… Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø­Ø±Ø§Ø¦Ù‚
st.title("ğŸ”¥ Fire Detection Monitoring System")
st.markdown("<h4 style='text-align: center; color: #FF5733;'>Ù†Ø¸Ø§Ù… Ù…Ø±Ø§Ù‚Ø¨Ø© Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø­Ø±ÙŠÙ‚</h4>", unsafe_allow_html=True)

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ YOLOv5
if "model" not in st.session_state:
    st.session_state.model = torch.hub.load('ultralytics/yolov5', 'custom','path='best.pt')

st.write("<div style='text-align: center;'>ğŸ‘€ Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø§Ù„Ø²Ø± Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©</div>", unsafe_allow_html=True)

# Ø²Ø± Ù„Ø¨Ø¯Ø¡ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
start_detection = st.button('ğŸš¨ Ø§Ø¨Ø¯Ø£ Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø­Ø±ÙŠÙ‚ ğŸš¨')

if "fire_detections" not in st.session_state:
    st.session_state.fire_detections = []
if "fire_images" not in st.session_state:
    st.session_state.fire_images = []

stframe = st.empty()
fire_images_placeholder = st.empty()

if start_detection:
    cap = cv2.VideoCapture(0)

    fire_classes = [0, 1, 2, 3, 4]
    conf_threshold = 0.5

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            st.write("âŒ Ø®Ø·Ø£ ÙÙŠ ÙØªØ­ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§")
            break

        results = st.session_state.model(frame)
        detections = results.pandas().xyxy[0]
        detections = detections[detections['confidence'] > conf_threshold]

        fire_detected = False
        for index, detection in detections.iterrows():
            if detection['class'] in fire_classes:
                fire_detected = True
                x1, y1, x2, y2 = int(detection['xmin']), int(detection['ymin']), int(detection['xmax']), int(detection['ymax'])
                confidence = detection['confidence'] * 100

                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)
                cv2.putText(frame, f"ğŸ”¥ Fire: {confidence:.2f}%", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

                now = datetime.now()
                timestamp = now.strftime("%Y-%m-%d %H:%M:%S")
                cv2.putText(frame, f"ğŸ•’ Detected at: {timestamp}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

                image_filename = f"fire_detected_{now.strftime('%Y%m%d_%H%M%S')}.jpg"
                cv2.imwrite(image_filename, frame)

                st.session_state.fire_images.insert(0, {'image': image_filename, 'timestamp': timestamp})
                st.session_state.fire_detections.insert(0, {'time': timestamp, 'image': image_filename, 'confidence': confidence})

                playsound('mixkit-urgent-simple-tone-loop-2976.wav')

        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img_pil = Image.fromarray(frame_rgb)
        stframe.image(img_pil, width=700)

        if st.session_state.fire_images:
            fire_images_placeholder.subheader("ğŸ”¥ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ÙƒØªØ´ÙØ©:")
            cols = fire_images_placeholder.columns(3)
            for idx, fire_image in enumerate(st.session_state.fire_images):
                cols[idx % 3].image(fire_image['image'], caption=f"ğŸ•’ {fire_image['timestamp']}", use_column_width=True)

    cap.release()
